# Source: https://github.com/cockroachdb/cockroach/blob/master/cloud/kubernetes/cockroachdb-statefulset.yaml
# Generated file, DO NOT EDIT. Source: cloud/kubernetes/templates/cockroachdb-statefulset.yaml
apiVersion: v1
kind: Service
metadata:
  labels: {app: bexhoma, component: sut, configuration: default, experiment: default}
  name: bexhoma-service
spec:
  ports:
  - {port: 9091, protocol: TCP, name: port-dbms, targetPort: 26257}
  - {port: 8080, protocol: TCP, name: port-web, targetPort: 8080}
  - {port: 9300, protocol: TCP, name: port-monitoring, targetPort: 9300}
  selector: {app: bexhoma, component: worker, configuration: default, experiment: default}
#metadata:
#  # This service is meant to be used by clients of the database. It exposes a ClusterIP that will
#  # automatically load balance connections to the different database pods.
#  name: cockroachdb-public
#  labels:
#    app: cockroachdb
#spec:
#  ports:
#  # The main port, served by gRPC, serves Postgres-flavor SQL, internode
#  # traffic and the cli.
#  - port: 26257
#    targetPort: 26257
#    name: grpc
#  # The secondary port serves the UI as well as health and debug endpoints.
#  - port: 8080
#    targetPort: 8080
#    name: http
#  selector:
#    app: cockroachdb
---
apiVersion: v1
kind: Service
metadata:
  # This service only exists to create DNS entries for each pod in the stateful
  # set such that they can resolve each other's IP addresses. It does not
  # create a load-balanced ClusterIP and should not be used directly by clients
  # in most circumstances.
  #name: cockroachdb
  name: bexhoma-worker
  labels: {app: bexhoma, component: worker, configuration: default, experiment: default}
  #labels:
  #  app: cockroachdb
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    #service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
    # Enable automatic monitoring of all instances when Prometheus is running in the cluster.
    #prometheus.io/scrape: "true"
    #prometheus.io/path: "_status/vars"
    #prometheus.io/port: "8080"
spec:
  ports:
  - {port: 26257, protocol: TCP, name: port-dbms, targetPort: 26257}
  - {port: 8080, protocol: TCP, name: port-web, targetPort: 8080}
  - {port: 9300, protocol: TCP, name: port-monitoring, targetPort: 9300}
  #- {port: 9300, protocol: TCP, name: port-monitoring, targetPort: 9300}
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other CockroachDB pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  clusterIP: None
  selector: {app: bexhoma, component: worker, configuration: default, experiment: default}
  #selector:
  #  app: cockroachdb
---
#apiVersion: policy/v1beta1
#kind: PodDisruptionBudget
#metadata:
#  name: cockroachdb-budget
#  labels:
#    app: cockroachdb
#spec:
#  selector:
#    matchLabels:
#      app: cockroachdb
#  maxUnavailable: 1
#---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: bexhoma-worker
  labels: {app: bexhoma, component: worker, configuration: default, experiment: default}
#metadata:
#  name: cockroachdb
spec:
  serviceName: bexhoma-workers
  #serviceName: "cockroachdb"
  replicas: 3
  selector:
    matchLabels:
      {app: bexhoma, component: worker, configuration: default, experiment: default}
  #selector:
  #  matchLabels:
  #    app: cockroachdb
  template:
    metadata:
      #labels:
      #  app: cockroachdb
      labels: {app: bexhoma, component: worker, configuration: default, experiment: default}
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - cockroachdb
              topologyKey: kubernetes.io/hostname
      automountServiceAccountToken: false
      imagePullSecrets:
      - {name: dockerhub}
      tolerations:
      - key: "nvidia.com/gpu"
        effect: "NoSchedule"
      containers:
      - name: cadvisor
        image: gcr.io/cadvisor/cadvisor:v0.47.0
        args: ["--port", "9300", "--storage_duration", "20m0s", "--docker_only", "true", "--disable_metrics", "disk,network,tcp,advtcp,udp,sched,process,hugetlb", "--application_metrics_count_limit", "30", "--housekeeping_interval", "5s"]
        ports:
        - containerPort: 9300
          #hostPort: 9300
          name: http
          protocol: TCP
        resources:
          requests:
            cpu: 150m
            memory: 200Mi
        volumeMounts:
        - name: rootfs
          mountPath: /rootfs
          readOnly: true
        - name: var-run
          mountPath: /var/run
          readOnly: true
        - name: sys
          mountPath: /sys
          readOnly: true
        - name: docker
          mountPath: /var/lib/docker
          readOnly: true
        - name: disk
          mountPath: /dev/disk
          readOnly: true
      - name: dbms
        image: cockroachdb/cockroach:v22.1.11
        imagePullPolicy: IfNotPresent
        # TODO: Change these to appropriate values for the hardware that you're running. You can see
        # the resources that can be allocated on each of your Kubernetes nodes by running:
        #   kubectl describe nodes
        # Note that requests and limits should have identical values.
        resources:
          limits: {cpu: 16000m, memory: 128Gi}
          requests: {cpu: 16000m, memory: 128Gi}
          #, ephemeral-storage: "1536Gi"}
        ports:
        - containerPort: 26257
          name: grpc
        - containerPort: 8080
          name: http
# We recommend that you do not configure a liveness probe on a production environment, as this can impact the availability of production databases.
#       livenessProbe:
#         httpGet:
#           path: "/health"
#           port: http
#         initialDelaySeconds: 30
#         periodSeconds: 5
        readinessProbe:
          httpGet:
            path: "/health?ready=1"
            port: http
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 2
        volumeMounts:
        - {mountPath: /cockroach/cockroach-data/extern/data, name: benchmark-data-volume}
        - name: bexhoma-workers
          mountPath: /cockroach/cockroach-data
        env:
        - name: BEXHOMA_WORKER_LIST
          value: cockroachdb-0.cockroachdb,cockroachdb-1.cockroachdb,cockroachdb-2.cockroachdb
        - name: COCKROACH_CHANNEL
          value: kubernetes-insecure
        - name: GOMAXPROCS
          valueFrom:
            resourceFieldRef:
              resource: limits.cpu
              divisor: "1"
        - name: MEMORY_LIMIT_MIB
          valueFrom:
            resourceFieldRef:
              resource: limits.memory
              divisor: "1Mi"
        command:
          - "/bin/bash"
          - "-ecx"
          # The use of qualified `hostname -f` is crucial:
          # Other nodes aren't able to look up the unqualified hostname.
          - exec
            /cockroach/cockroach
            start
            --logtostderr
            --insecure
            --advertise-host $(hostname -f)
            --http-addr 0.0.0.0
            --join $(expr $BEXHOMA_WORKER_LIST)
            --cache $(expr $MEMORY_LIMIT_MIB / 4)MiB
            --max-sql-memory $(expr $MEMORY_LIMIT_MIB / 4)MiB
      # No pre-stop hook is required, a SIGTERM plus some time is all that's
      # needed for graceful shutdown of a node.
      terminationGracePeriodSeconds: 60
      volumes:
      - name: benchmark-data-volume
        persistentVolumeClaim: {claimName: bexhoma-data}
      - name: bexhoma-workers
        persistentVolumeClaim: {claimName: bexhoma-workers}
      - name: rootfs
        hostPath:
          path: /
      - name: var-run
        hostPath:
          path: /var/run
      - name: sys
        hostPath:
          path: /sys
      - name: docker
        hostPath:
          path: /var/lib/docker
      - name: disk
        hostPath:
          path: /dev/disk
      - name: dshm
        emptyDir:
          medium: Memory
      #- name: datadir
      #  persistentVolumeClaim:
      #    claimName: datadir
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: bexhoma-workers
      labels: {app: bexhoma, component: worker, configuration: default, experiment: default}
    spec:
      accessModes:
        - "ReadWriteOnce"
      resources:
        requests:
          storage: 100Gi
      storageClassName: shared
---
# Generated file, DO NOT EDIT. Source: cloud/kubernetes/templates/cluster-init.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: cluster-init
  labels:
    app: cockroachdb
spec:
  template:
    spec:
      containers:
      - name: cluster-init
        image: cockroachdb/cockroach:v22.1.11
        imagePullPolicy: IfNotPresent
        env:
        - name: BEXHOMA_WORKER_LIST
          value: cockroachdb-0.cockroachdb,cockroachdb-1.cockroachdb,cockroachdb-2.cockroachdb
        env:
        - name: BEXHOMA_WORKER_FIRST
          value: cockroachdb-0.cockroachdb
        command:
          - "/bin/bash"
          - "-ecx"
          # The use of qualified `hostname -f` is crucial:
          # Other nodes aren't able to look up the unqualified hostname.
          - exec
            /cockroach/cockroach
            init
            --insecure
            --host=$(expr $BEXHOMA_WORKER_FIRST)
      restartPolicy: OnFailure
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels: {app: bexhoma, component: sut, configuration: default, experiment: default}
  name: bexhoma-deployment-cockroachdb
spec:
  replicas: 1
  selector:
    matchLabels: {app: bexhoma, component: sut, configuration: default, experiment: default}
  template:
    metadata:
      labels: {app: bexhoma, component: sut, configuration: default, experiment: default}
    spec:
      automountServiceAccountToken: false
      imagePullSecrets:
      - {name: dockerhub}
      nodeSelector:
      tolerations:
      - key: "nvidia.com/gpu"
        effect: "NoSchedule"
      containers:
      - name: dbms
        image: cockroachdb/cockroach:v22.1.11
        env:
        ports:
        - containerPort: 26257
        resources:
          limits: {cpu: 100m, memory: 1Gi}
          requests: {cpu: 100m, memory: 16Gi}
        command: ["/bin/sh"]
        args: ["-c", "while true; do echo hello; sleep 10;done"]
        volumeMounts:
        - {mountPath: /data, name: benchmark-data-volume}
      volumes:
      - name: benchmark-data-volume
        persistentVolumeClaim: {claimName: bexhoma-data}
